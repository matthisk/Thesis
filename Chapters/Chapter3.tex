% Chapter Template

\chapter{Transforming ECMAScript 6} % Main chapter title

\label{Chapter3}

\lhead{Chapter 3. \emph{Transforming ECMAScript 6}}

\section{Motivating Examples}

The Babeljs compiler visits each AST node, functions inside of a specific transformation can announce themselves for the callback stack of a node visit. The callback to this function receives several arguments (current AST node, parent AST node, current Scope, and the file being transformed). The Scope class has functions presented in \ref{babel-scope}, if a node transformation wants to introduce a new variable say $ref$ it calls $generateUidIdentifier$ with String $ref$ as an argument on Scope and receives a name which is not bound in the current Scope. For this to work the visitor needs to have information of all the variables bound in the current scope. This makes the transformation more a full compiler than a set of transformation rules. For starters the transformation code needs to be aware of the Scope class and its functions. 

\begin{lstlisting}[label=babel-scope, caption={Variable capture avoidance code from babeljs source\protect\footnotemark}]
  generateUidIdentifier(name: string) {
    return t.identifier(this.generateUid(name));
  }

  generateUid(name: string) {
    name = t.toIdentifier(name).replace(/^_+/, "");

    var uid;
    var i = 0;
    do {
      uid = this._generateUid(name, i);
      i++;
    } while (this.hasBinding(uid) || this.hasGlobal(uid) || this.hasReference(uid));


    var program = this.getProgramParent();
    program.references[uid] = true;
    program.uids[uid] = true;

    return uid;
  }

  _generateUid(name, i) {
    var id = name;
    if (i > 1) id += i;
    return `_${id}`;
  }
\end{lstlisting}
\footnotetext{\href{https://goo.gl/BZKIvV}{https://goo.gl/BZKIvV}}

The Traceur compiler totally ignores the problem of variable capture. In conformance with the case study conducted by Erdeweg et. al. \cite{Erdweg2014} we were able to identify a transpiler that fails to address variable capture. With a simple example we can demonstrate the introduction of capture by Traceur \ref{traceur-capture}

\begin{lstlisting}[label=traceur-capture, caption=Example input to Traceur\protect\footnotemark]
function f() {
  var $__0 = 0;
  var x = () => this; 
}
\end{lstlisting}
\footnotetext{\href{https://goo.gl/Ds3xUn}{https://goo.gl/Ds3xUn}}

\begin{lstlisting}[caption=Variable capture]
function f() {
    var $__0 = this;
    var $__0 = 0;
    var x = (function() {
      return $__0;
    });
  }
\end{lstlisting}

\section{Taxonomy of language features} \label{taxonomy}

Every language extension has several properties which can be identified and categorized along certain dimensions. In this chapter we present a taxonomy for language extensions. In appendix \ref{AppendixB} we categorize ES6 language features according to this model.

\subsection{Dimensions}
The following dimensions are identified and used to categorize every language extension.

\paragraph{Category}
One of the rephrasing categories defined by Eelco Visser\cite{Visser2001}, rephrasings are program transformations where source and target program language are the same. Each category is explained in table \ref{table-rephrasing-categories}.

\begin{table}[h]
\centering
\caption{Rephrasing categories}
\def\arraystretch{1.5}
\label{table-rephrasing-categories}
\begin{tabular}{p{0.2\linewidth}p{0.8\linewidth}}
\multicolumn{1}{l}{Normalization} & The reduction of a source program to a target program in a sub-language of the source program language.                                                                                                                                                                               
\\
\multicolumn{1}{r}{\bf Desugaring}                  & a language construct (called syntactic sugar) is reduced to a core language.                                                    \\
\multicolumn{1}{r}{\bf Simplification}              & this is a more generic form of normalization in which parts of the program are transformed to a standard form, with the goal of simplifying the program without changing the semantics. \\
\multicolumn{1}{r}{\bf Weaving}                     & this transformation injects functionality in a source program, without modifying the code. It is used in aspect-oriented programming, where cross-cutting concerns are separated from the main code and later 'weaved' with the main program through a aspect weaver.)                                                                                                                                                                               \\
\\
\multicolumn{1}{l}{Optimization}  & These transformations help improve the run-time and/or space performance of a program                                                                                         \\
\multicolumn{1}{r}{\bf Specialization}              & Code specialization deals with code that runs with a fixed set of parameters. When it is known that some function will run with some parameters fixed the function can be optimized for these values before run-time. (e.g. compiling a regular expression before execution).                                                                                                                                                                               \\
\multicolumn{1}{r}{\bf Inlining}                    & Transform code to inline a certain (standard) function within your function body, instead of calling the function from the (standard) library. This produces a slight performance increase because we avoid an additional function call. (this technique is more common in lower level programming languages e.g. C or C++)                                                                                                                                                                              \\
\multicolumn{1}{r}{\bf Fusion}                      & Fusion merges two bodies of loops (or recursive code) that do not share references and loop over the same range, with the goal to reduce run-time of the program.                                                                                                                                                                               \\
\\
\multicolumn{1}{l}{Other}         &                                                                                                                                                                               \\
\multicolumn{1}{r}{\bf Refactoring}                 & "is a disciplined technique for restructuring an existing body of code, alteringits internal structure without changing its external behaviour."\footnotemark                 \\
\multicolumn{1}{r}{\bf Obfuscation}                 & is a transformation that makes output code less (human) readable, while not changing any of the semantics.                                                                    \\
\multicolumn{1}{r}{\bf Renovation}                  & is a special form of refactoring, "\textit{to repair an error or to bring it up to date with respect to changed requirements"}~\cite{Visser2001}                                                
\end{tabular}
\end{table}
\footnotetext{\url{http://www.refactoring.com}}

\paragraph{Abstraction level}
Program transformations can be categorized by their abstraction level. There are four levels of abstraction (similar to those of macro expansions~\cite{Weise1993}), character-, token-, syntax-, or semantic-based. Character and token based transformations work on a program in textual representation. Syntactical transformations work on a program in its parsed representation (either as an AST or as a parse tree, see section \ref{program-representation}). Next to the syntactic representation semantic transformations also have access to the static semantics of the input program (e.g. variable binding).

\paragraph{Extension or Modification}
Rephrasings (identified above) try to say the same thing (i.e. no change in semantics) but using different words\cite{Visser2001}. Sometimes these different words are an extension on the core language, in this case we call the transformation a \textit{program extension}. In other cases the transformation uses only the words available in the core language, then we call the transformation a \textit{program modification}. Transformations that fall in the \textit{optimization} (see table \ref{table-rephrasing-categories}) category are program modifications. An example is tail call optimization in which a recursive function call in the \textit{return} statement is reduced to a loop to avoid a call-stack overflow error (see section \ref{tail-call-optimization}). 

\paragraph{Scope}
Program transformations can happen within four different scopes: 

When a program transformation matches on a sub-tree of the parse-tree and only transforms this matched sub-tree it is a \textit{(1) local-to-local} transformation. If the transformation needs information outside the context of the matched sub-tree, but only transforms the matched sub-tree it is \textit{(2) global-to-local}. When a transformation has no additional context from its local sub-tree but does alter the entire parse-tree it is called \textit{(3) local-to-global}. If the transformation transforms the input program in its entirety it is \textit{(4) global-to-global}.  

\paragraph{Syntactically type preserving}
Program transformations performed on syntax elements can preserve the syntactical type of their input element or alter it. Two main syntactical types in JavaScript are Statement and Expression (see section \ref{javascript-syntax}). If a transformation matches on a Expression node but returns a Statement it is non syntactical type preserving.

\paragraph{Introduction of bindings}
Does the transformation introduce new bindings. Transformations that do not introduce bindings are guaranteed to be hygienic (see section \ref{hygiene}), where binding introducing transformations can cause variable capture from transformation bindings to source bindings.

\paragraph{Depending on bindings (i.e. run-time code)}
Will the target program produced by the transformation depend on context not introduced by the transformation (e.g. global variables, external libraries).

\paragraph{Compositional}
When a program transformation does not alter the containing context of the matched parse-tree node, it is said to be compositional. The main concern of compositionality of program transformations is if the transformation can be reversed or not.
\\ 
A parse-tree node with context $C$ and children context $C[x]$ is transformed to context $C'$ with children context $C'[x]$ where $x$ is unchanged.

\paragraph{Preconditions}
What are the preconditions that have to be met before execution of a transformation rule, to ensure validity of the transformation (e.g. all sub-terms have to be analyzed and transformed)

\paragraph{Restrictions on sub-terms}
Does the language extensions impose restrictions on the sub-terms used inside of the language extension. 

\paragraph{Analysis of sub-terms}
Are the non-terminals of our language extension analyzed and possibly transformed by the transformation rule.

\paragraph{Dependency on other extensions}
Can the language extensions be performed stand-alone or is there a dependency on one of the other extensions.

\paragraph{Backwards compatible}
Is the API of the transformed code compatible with the ECMAScript 6 specification (i.e. can we import a transformed module in ECMAScript 6 and use it properly).

\paragraph{Decomposable}
Is it possible to identify smaller transformation rules inside this language extension, that can be performed independently from one another.

\afterpage{%
	\clearpage
	\thispagestyle{headings}
	
	\begin{landscape}		
		\centering

		\begin{table}[h]
		\caption{ES6 features transformation dimensions}
		\label{full-table}

\begin{tabular}{rcccccc}
\hline
& {\bf Arrow Functions} & {\bf Classes} & {\bf Destructuring} & {\bf Object literals} & {\bf For of loop} & {\bf Spread operator} \\ \hline
{\bf Category} & D. & D. & D. & D. & D. & D. \\
{\bf Abstraction level} & CfS. & CfS. & CfS. & CfS. & CfS. & CfS. \\
{\bf Scope} & G2L & L2L & L2L & L2L & L2L & L2L \\
{\bf Extension or Modification} & E. & E. & E. & E. & E. & E. \\
{\bf Syntactically type preserving} & $\bullet$ & $\bullet$ & $\circ$ & $\bullet$ & $\bullet$ & $\bullet$ \\
{\bf Introducing bindings} & $\bullet$ & $\circ$ & $\bullet$ & $\circ$ & $\circ$ & $\bullet$ \\
{\bf Depending on bindings} & $\circ$ & $\bullet$ & $\bullet$ & $\circ$ & $\circ$ & $\bullet$ \\
{\bf Compositional} & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ \\
{\bf Analysis of subterms} & $\bullet$ & $\bullet$ & $\bullet$ & $\circ$ & $\circ$ & $\bullet$  \\
{\bf Constraints on subterms} & $\circ$ & $\bullet$ & $\circ$ & $\circ$ & $\circ$ & $\circ$   \\
{\bf Preconditions} & $\bullet$ & $\bullet$ & $\circ$ & $\circ$ & $\circ$ & $\circ$   \\
{\bf Dependencies}  & $\circ$ & $\circ$ & $\bullet$ & $\circ$ & $\bullet$ & $\circ$   \\
{\bf Backwards compatible} & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$  \\
{\bf Decomposable} & $\circ$ & $\circ$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$  \\ \hline
\end{tabular}
\vspace*{0.5cm}
\newline

\begin{tabular}{rcccccc}
\hline
& {\bf Default parameters} & {\bf Rest parameters} & {\bf Template Literals} & {\bf Generators} & {\bf Let Const} & {\bf Tail call} \\ \hline
{\bf Category} & D. & D. & D. & D. & U. & Opt. \\
{\bf Abstraction level} & CfS. & CfS. & CfS. & CfS. & S. & CfS. \\
{\bf Scope} & L2L & L2L & L2L & L2L & G2G & L2L \\
{\bf Extension or Modification} & E. & E. & E. & E. & E. & M. \\
{\bf Syntactically type preserving} & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$  & $\bullet$      \\
{\bf Introducing bindings} & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\bullet$ & $\circ$ \\
{\bf Depending on bindings} & $\circ$ & $\circ$ & $\circ$ & $\bullet$ & $\circ$ & $\circ$ \\
{\bf Compositional} & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\circ$ & $\circ$ \\
{\bf Analysis of subterms} & $\circ$ & $\circ$ & $\circ$ & $\bullet$ & $\bullet$ & $\bullet$ \\
{\bf Constraints on subterms} & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\circ$ \\
{\bf Preconditions} & $\circ$ & $\circ$ & $\circ$ & $\bullet$ & $\bullet$ & $\circ$ \\
{\bf Dependencies} & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\circ$ \\
{\bf Backwards compatible} & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\circ$ & $\bullet$ \\
{\bf Decomposable} & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\bullet$ & $\circ$ \\ \hline
\end{tabular}
\caption*{$\bullet$: Yes, $\circ$: No, \textbf{D}: Desugaring, \textbf{U}: Undefined, \textbf{Opt}: Optimization, \textbf{CfS}: Context-free-syntax, \textbf{L2L}: local-to-local, \textbf{E}: Extension, \textbf{M}: Modification}
	\end{table}

		
	\end{landscape}
	\clearpage
}

\subsection{On the expressive power of ECMAScript 6}
Matthias Felleisen presents a rigorous mathematical framework to define the expressiveness of programming languages (as compared to each other) in his paper "On the expressive power of programming languages"\cite{Felleisen1990}. 

The formal specification presented by Felleisen falls outside of the scope of this thesis. But we can summaries his findings informally: If a construct in language $A$ can be expressed in a construct in language $B$ by only performing local transformations (\textit{local-to-local}), then language $A$ is no more expressive than language $B$. And \textit{"By the definition of an expressible construct, programs in a less expressive language generally have a globally different structure from functionally equivalent programs in a more expressive language."}\cite{Felleisen1990} 

This implies that every language extension transformed through a \textit{local-to-local} scoped transformation (see section \ref{taxonomy}), creates a language that is no more expressive than the original (core) language. In table \ref{full-table} the categorization of ECMAScript 6 language extensions is displayed. Ten of the twelve extensions can be transformed with the use of a \textit{local-to-local} transformation, the two exceptions are, the extension of binding constructs (see appendix \ref{let-const}). This extension requires a \textit{global-to-global} transformation. And the arrow function (see appendix \ref{arrow}) which requires a \textit{global-to-local} transformation, because the transformation depends on the context in which the arrow function is used (i.e. either the global scope or inside a function).

\textit{"Intuitively, a programming language is less expressive than another if the latter can express all the facilities the former can express in the language universe."}~\cite{Felleisen1990}. Thus ES6 is more expressive than ES5.

\section{Implementation}
Each transformation is defined as a rewrite rule. It has a concrete syntax pattern which matches part of a parse-tree. The result is a concrete piece of syntax, using only constructs from the core syntax definition (i.e. ECMAScript 5).
The rewrite rules are exhaustively applied on the input parse-tree until no more rewrite rules match any sub-trees of the input. Application of rewrite rules to the parse-tree is done bottom-up, because several rewrite rules (e.g. arrow function) demand their sub-terms to be transformed to guarantee successful completion.

\subsection{cross-cutting concerns}
Each transformation rule has to deal with similar issues, can we identify these issues and solve them in a standalone (language agnostic) fashion?
Many problems with transformations originate with name binding in source and target language.

\paragraph{Variable capture}
In section \ref{hygiene} we have described the problem of variable capture in the context of program transformations. To solve this problem for our transformation suite we reuse the \textit{name-fix} algorithm presented by Erdweg et. al.~\cite{Erdweg2014}. The algorithm relies on a binding graph to identify variable capture, and uses string origins~\cite{Inostroza2014} to distinguish between synthesized identifiers (i.e. those identifiers introduced by the transformation) and identifiers originating from the source program.

\textit{name-fix} analyses the \textit{name graph} of source and target program to identify variable capture. The name graph contains nodes for all identifiers in the program, a directed edge indicates a reference to a declaration. 



\begin{figure}[h]
\centering

\begin{minipage}{0.25\linewidth}

\begin{lstlisting}
	var x = 0, 
		tmp = 1;
		
	(function() {
		var tmp = x;
		x = tmp;
		tmp = tmp;
	})();
\end{lstlisting}

\end{minipage}
\hfill
\begin{minipage}{0.65\linewidth}

\begin{tikzpicture}[
source/.style={circle, draw=black, fill=white, very thick, minimum size=10mm},
synthesized/.style={circle, draw=black, fill=gray!60, very thick, minimum size=10mm}
]
\node[source](x_dec){1:x};
\node[source](tmp_dec)[right=of x_dec]{2:t};
\node[synthesized](tmp_dec_2)[right=of tmp_dec]{5:t};

\node[source](x_ref)[below=of x_dec,xshift=7mm]{5:x};
\node[source](x_ref_2)[below=of x_dec,xshift=-7mm]{6:x};
\node[source](tmp_ref)[below=of tmp_dec_2,xshift=-7mm]{6:t};
\node[synthesized](tmp_ref_2)[below=of tmp_dec_2,xshift=7mm]{7:t};

\node[source](tmp_ref_3)[below=of tmp_dec]{7:t};

\draw[->] (x_ref.north) -- (x_dec.south);
\draw[->] (x_ref_2.north) -- (x_dec.south);
\draw[->] (tmp_ref.north) -- (tmp_dec_2.south);
\draw[->] (tmp_ref_2.north) -- (tmp_dec_2.south);
\draw[->] (tmp_ref_3.north) -- (tmp_dec_2.south);
\end{tikzpicture}

\end{minipage}

\caption{Name graph produced from code} \label{fig:name-graph}
\end{figure}

\begin{figure}[h]
\centering
\begin{tikzpicture}[
source/.style={circle, draw=black, fill=white, very thick, minimum size=10mm},
synthesized/.style={circle, draw=black, fill=gray!60, very thick, minimum size=10mm}
]
\node[source](x_dec){1:x};
\node[source](tmp_dec)[right=of x_dec]{2:t};
\node[synthesized](tmp_dec_2)[right=of tmp_dec]{5:t'};

\node[source](x_ref)[below=of x_dec,xshift=7mm]{5:x};
\node[source](x_ref_2)[below=of x_dec,xshift=-7mm]{6:x};
\node[source](tmp_ref)[below=of tmp_dec,xshift=7mm]{6:t};
\node[synthesized](tmp_ref_2)[below=of tmp_dec_2]{7:t'};

\node[source](tmp_ref_3)[below=of tmp_dec,xshift=-7mm]{7:t};

\draw[->] (x_ref.north) -- (x_dec.south);
\draw[->] (x_ref_2.north) -- (x_dec.south);
\draw[->] (tmp_ref.north) -- (tmp_dec.south);
\draw[->] (tmp_ref_2.north) -- (tmp_dec_2.south);
\draw[->] (tmp_ref_3.north) -- (tmp_dec.south);
\end{tikzpicture}
\caption{Name graph after name-fix is applied} \label{fig:name-graph-fixed}
\end{figure}

Because our source and target language are both JavaScript and thus have the same binding mechanism, we only generate the name graph for our target program. 


What are some possible solutions for this problem. Let each transformation deal with the avoidance of variable capture. Build full scope tree and supply this scope to our \textit{desugaring} functions, generate new identifiers that are unique in the scope. Disadvantage of this solution is that programmers creating transformation code need also be capable of creating scope trees, and our transformer start to have more resemblance with full fledged compiler than term-rewriting rules.

The solution presented by Erdweg et. al.\cite{Erdweg2014a} is called \textit{name-fix}, this is a standalone algorithm that does not interfere with transformation code. It identifies variable capture through the use of string origin\cite{Inostroza2014} information stored in the parse-tree.

\paragraph{Introducing (multiple) bindings}
As described above various desugarings have to introduce bindings for correct transformation. In most cases new bindings will be bound to some descriptive variable name (e.g. \_ref). If a language extension is used multiple times within the same scope the same identifier will be declared multiple times. This is a similar problem to that of variable capture, but the capture now happens with binding all introduced by transformation code. And not from a transformation to source binding. Similar to the variable capture problem this problem could be solved uniquely for every transformation, or can be extracted and solved in a generic manner (i.e. agnostic from transformation code). 

Supply each \textit{desugar} function with a function called \textit{generateUId} (generate unique identifier). When a transformation wants to generate a identifier (.e.g \_ref), it calls this function (which has knowledge of all previously generated identifiers) and generates a unique identifier through the use of \textit{gensym}\ref{gen-sym} algorithm. 
