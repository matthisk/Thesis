% Chapter Template

\chapter{Transforming ECMAScript 6} % Main chapter title

\label{Chapter3}

\lhead{Chapter 3. \emph{Transforming ECMAScript 6}}

\section{Taxonomy of language extensions} \label{taxonomy}

Every language extension has several properties which can be identified and categorized along certain dimensions. In this chapter we present a taxonomy for language extensions. In appendix \ref{AppendixB} we categorize ES6 language features according to this taxonomy.

\subsection{Dimensions}
The following dimensions are identified and used to categorize every language extension.

\paragraph{Category}
One of the rephrasing categories defined by Eelco Visser~\cite{Visser2001}, rephrasings are program transformations where source and target program language are the same. Each category is explained in table \ref{table-rephrasing-categories}.

\begin{longtable}{p{0.2\textwidth}p{0.75\textwidth}}
\multicolumn{1}{l}{Normalization} & The reduction of a source program to a target program in a sub-language of the source program language.                                                                                                                                                                               
\\ \hline \\
\multicolumn{1}{r}{\bf Desugaring}                  & a language construct (called syntactic sugar) is reduced to a core language.                                                    \\
\multicolumn{1}{r}{\bf Simplification}              & this is a more generic form of normalization in which parts of the program are transformed to a standard form, with the goal of simplifying the program without changing the semantics. \\
\multicolumn{1}{r}{\bf Weaving}                     & this transformation injects functionality in a source program, without modifying the code. It is used in aspect-oriented programming, where cross-cutting concerns are separated from the main code and later 'weaved' with the main program through a aspect weaver.)                                                                                                                                                                               \\
\\
\multicolumn{1}{l}{Optimization}  & These transformations help improve the run-time and/or space performance of a program                                                                                         \\ \hline \\
\multicolumn{1}{r}{\bf Specialization}              & Code specialization deals with code that runs with a fixed set of parameters. When it is known that some function will run with some parameters fixed the function can be optimized for these values before run-time. (e.g. compiling a regular expression before execution).                                                                                                                                                                               \\
\multicolumn{1}{r}{\bf Inlining}                    & Transform code to inline a certain (standard) function within your function body, instead of calling the function from the (standard) library. This produces a slight performance increase because we avoid an additional function call. (this technique is more common in lower level programming languages e.g. C or C++)                                                                                                                                                                              \\
\multicolumn{1}{r}{\bf Fusion}                      & Fusion merges two bodies of loops (or recursive code) that do not share references and loop over the same range, with the goal to reduce run-time of the program.                                                                                                                                                                               \\
\\
\multicolumn{1}{l}{Other}         &                                                                                                                                                                               \\ \hline \\
\multicolumn{1}{r}{\bf Refactoring}                 & "\textit{is a disciplined technique for restructuring an existing body of code, alteringits internal structure without changing its external behaviour.}"\footnotemark                 \\
\multicolumn{1}{r}{\bf Obfuscation}                 & is a transformation that makes output code less (human) readable, while not changing any of the semantics.                                                                    \\
\multicolumn{1}{r}{\bf Renovation}                  & is a special form of refactoring, "\textit{to repair an error or to bring it up to date with respect to changed requirements"}~\cite{Visser2001} \\                                               
\caption{Rephrasing categories} \label{table-rephrasing-categories}
\end{longtable}
\footnotetext{\url{http://www.refactoring.com}}

\paragraph{Abstraction level}
Program transformations can be categorized by their abstraction level. There are four levels of abstraction (similar to those of macro expansions~\cite{Weise1993}), character-, token-, syntax-, or semantic-based. Character and token based transformations work on a program in textual representation. Syntactical transformations work on a program in its parsed representation (either as an AST or as a parse tree, see section \ref{program-representation}). In addition to the syntactic representation semantic transformations also have access to the static semantics of the input program (e.g. variable binding).

\paragraph{Extension or Modification}
Rephrasings try to say the same thing (i.e. no change in semantics) but using different words\cite{Visser2001}. Sometimes these different words are an extension on the core language, in this case we call the transformation a \textit{program extension}. In other cases the transformation uses only the words available in the core language, then we call the transformation a \textit{program modification}. Transformations that fall in the \textit{optimization} category (see table \ref{table-rephrasing-categories}) are program modifications. An example is tail call optimization in which a recursive function call in the \textit{return} statement is reduced to a loop to avoid a call-stack overflow error (see appendix \ref{tail-call-optimization}). 

\paragraph{Scope}
Program transformations performed on the abstraction level of context-free syntax (or semantics) receive the parse tree of the source program as their input. A transformation searches the parse tree for a specific type of node, the type of node to match on is defined by the transformation and can be any syntactical type defined in the source program's grammar. The node matched by a transformation and whether or not information from outside this node's scope is used during transformation determine the scope of a program transformation, there are four different scopes:

When a program transformation matches on a sub-tree of the parse-tree and only transforms this matched sub-tree it is a \textit{(1) local-to-local} transformation. If the transformation needs information outside the context of the matched sub-tree, but only transforms the matched sub-tree it is \textit{(2) global-to-local}. When a transformation has no additional context from its local sub-tree but does alter the entire parse-tree it is called \textit{(3) local-to-global}. If the transformation transforms the input program in its entirety it is \textit{(4) global-to-global}.  

\paragraph{Syntactically type preserving}
Program transformations performed on syntax elements can preserve the syntactical type of their input element or alter it. Two main syntactical types in JavaScript are Statement and Expression (see section \ref{javascript-syntax}). If a transformation matches on a Expression node but returns a Statement it is non syntactical type preserving.

\paragraph{Introduction of bindings}
Does the transformation introduce new bindings. Transformations that do not introduce bindings are guaranteed to be hygienic (see section \ref{hygiene}), where binding introducing transformations can cause variable capture from synthesized bindings to source bindings.

\paragraph{Depending on bindings (i.e. run-time code)}
Will the target program produced by the transformation depend on context not introduced by the transformation (e.g. global variables, external libraries).

\paragraph{Compositional}
When a program transformation does not alter the containing context of the matched parse-tree node, it is said to be compositional. The main concern of compositionality of program transformations is if the transformation can be reversed or not.

\paragraph{Preconditions}
What are the preconditions that have to be met before execution of a transformation rule, to ensure validity of the transformation (e.g. all sub-terms have to be analyzed and transformed)

\paragraph{Restrictions on sub-terms}
Does the language extensions impose restrictions on the terms used inside of the language extension's non-terminals. For example we can only use identifiers in the sub-terms of our \lstinline$swap$ language extension (see section \ref{hygiene}). 

\paragraph{Analysis of sub-terms}
Are the non-terminals of our language extension analyzed by the transformation rule. This is related to compositionality but differs because compositional transformations analyze \textit{and transform} sub-terms.

\paragraph{Dependency on other extensions}
Can the language extensions be performed stand-alone or is there a dependency on one of the other extensions.

\paragraph{Backwards compatible}
Is the API of the transformed code compatible with the ECMAScript 6 specification (i.e. can we import a transformed module in ECMAScript 6 and use it properly).

\paragraph{Decomposable}
Is it possible to identify smaller transformation rules inside this language extension, that can be performed independently from one another.

	
	\begin{landscape}		
		\centering

		\begin{table}[h]
		\caption{ES6 features transformation dimensions}
		\label{full-table}

\begin{tabular}{rcccccc}
\hline
& {\bf Arrow Functions} & {\bf Classes} & {\bf Destructuring} & {\bf Object literals} & {\bf For of loop} & {\bf Spread operator} \\ \hline
{\bf Category} & D. & D. & D. & D. & D. & D. \\
{\bf Abstraction level} & CfS. & CfS. & CfS. & CfS. & CfS. & CfS. \\
{\bf Scope} & G2L & L2L & L2L & L2L & L2L & L2L \\
{\bf Extension or Modification} & E. & E. & E. & E. & E. & E. \\
{\bf Syntactically type preserving} & $\bullet$ & $\bullet$ & $\circ$ & $\bullet$ & $\bullet$ & $\bullet$ \\
{\bf Introducing bindings} & $\bullet$ & $\circ$ & $\bullet$ & $\circ$ & $\circ$ & $\bullet$ \\
{\bf Depending on bindings} & $\circ$ & $\bullet$ & $\bullet$ & $\circ$ & $\circ$ & $\bullet$ \\
{\bf Compositional} & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ \\
{\bf Analysis of subterms} & $\bullet$ & $\bullet$ & $\bullet$ & $\circ$ & $\circ$ & $\bullet$  \\
{\bf Constraints on subterms} & $\circ$ & $\bullet$ & $\circ$ & $\circ$ & $\circ$ & $\circ$   \\
{\bf Preconditions} & $\bullet$ & $\bullet$ & $\circ$ & $\circ$ & $\circ$ & $\circ$   \\
{\bf Dependencies}  & $\circ$ & $\circ$ & $\bullet$ & $\circ$ & $\bullet$ & $\circ$   \\
{\bf Backwards compatible} & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$  \\
{\bf Decomposable} & $\circ$ & $\circ$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$  \\ \hline
\end{tabular}
\vspace*{0.5cm}
\newline

\begin{tabular}{rcccccc}
\hline
& {\bf Default parameters} & {\bf Rest parameters} & {\bf Template Literals} & {\bf Generators} & {\bf Let Const} & {\bf Tail call} \\ \hline
{\bf Category} & D. & D. & D. & D. & U. & Opt. \\
{\bf Abstraction level} & CfS. & CfS. & CfS. & CfS. & S. & CfS. \\
{\bf Scope} & L2L & L2L & L2L & L2L & G2G & L2L \\
{\bf Extension or Modification} & E. & E. & E. & E. & E. & M. \\
{\bf Syntactically type preserving} & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$  & $\bullet$      \\
{\bf Introducing bindings} & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\bullet$ & $\circ$ \\
{\bf Depending on bindings} & $\circ$ & $\circ$ & $\circ$ & $\bullet$ & $\circ$ & $\circ$ \\
{\bf Compositional} & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\circ$ & $\circ$ \\
{\bf Analysis of subterms} & $\circ$ & $\circ$ & $\circ$ & $\bullet$ & $\bullet$ & $\bullet$ \\
{\bf Constraints on subterms} & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\circ$ \\
{\bf Preconditions} & $\circ$ & $\circ$ & $\circ$ & $\bullet$ & $\bullet$ & $\circ$ \\
{\bf Dependencies} & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\circ$ \\
{\bf Backwards compatible} & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\circ$ & $\bullet$ \\
{\bf Decomposable} & $\circ$ & $\circ$ & $\circ$ & $\circ$ & $\bullet$ & $\circ$ \\ \hline
\end{tabular}
\caption*{$\bullet$: Yes, $\circ$: No, \textbf{D}: Desugaring, \textbf{U}: Undefined, \textbf{Opt}: Optimization, \textbf{CfS}: Context-free-syntax, \textbf{L2L}: local-to-local, \textbf{E}: Extension, \textbf{M}: Modification}
	\end{table}

		
	\end{landscape}


\section{Implementation}
Each transformation is defined as a rewrite rule. It has a concrete syntax pattern which matches part of a parse-tree. The result is a concrete piece of syntax, using only constructs from the core syntax definition (i.e. ES 5).
The rewrite rules are exhaustively applied on the input parse-tree until no more rewrite rules match any sub-trees of the input. Application of rewrite rules to the parse-tree is done bottom-up, because several rewrite rules (e.g. arrow function) demand their sub-terms to be transformed to guarantee successful completion.

\subsection{cross-cutting concerns}
Each transformation rule has to deal with similar issues, can we identify these issues and solve them in a standalone (language agnostic) fashion?
Many problems with transformations originate with name binding in source and target language.

\paragraph{Variable capture}
In section \ref{hygiene} we have described the problem of variable capture in the context of program transformations. To solve this problem for our transformation suite we reuse the \textit{name-fix} algorithm presented by Erdweg et. al.~\cite{Erdweg2014}. The algorithm relies on a binding graph to identify variable capture, and uses string origins~\cite{Inostroza2014} to distinguish between synthesized identifiers (i.e. those identifiers introduced by the transformation) and identifiers originating from the source program.

\textit{name-fix} analyses the \textit{name graph} of source and target program to identify variable capture. The name graph contains nodes for all identifiers in the program, a directed edge indicates a reference to a declaration. Because our source and target language are both JavaScript and thus have the same binding mechanism, we only generate the name graph for our target program. In the graph a distinction is made between synthesized and user bindings. To identify whether a binding originates from the source program or was synthesized during transformation, the \textit{name-fix} algorithm uses string origins~\cite{Inostroza2014}. 

In figure \ref{fig:name-graph} we use the target program from our \lstinline$swap$ language extension (see section \ref{hygiene}) to illustrate how these name graphs are constructed, and how \textit{name-fix} identifies variable capture. Each node contains a line number and the identifier it resembles from that line, a directed edge is a reference to a declaration. Nodes with a white background originate from the source program, nodes with a dark background are synthesized during transformation. Line numbers from synthesized identifiers are appended with a tick.

\begin{figure}[h]
\centering
\begin{minipage}{0.25\linewidth}
\begin{lstlisting}
	var x = 0, 
		tmp = 1;
		
	(function() {
		var tmp = x;
		x = tmp;
		tmp = tmp;
	})();
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.65\linewidth}
\begin{tikzpicture}[
source/.style={circle, draw=black, fill=white, very thick, minimum size=10mm},
synthesized/.style={circle, draw=black, fill=gray!60, very thick, minimum size=10mm}
]
\node[source](x_dec){1:x};
\node[source](tmp_dec)[right=of x_dec]{2:t};
\node[synthesized](tmp_dec_2)[right=of tmp_dec]{5':t};

\node[source](x_ref)[below=of x_dec,xshift=7mm]{5:x};
\node[source](x_ref_2)[below=of x_dec,xshift=-7mm]{6:x};
\node[source](tmp_ref)[below=of tmp_dec_2,xshift=-7mm]{6:t};
\node[synthesized](tmp_ref_2)[below=of tmp_dec_2,xshift=7mm]{7':t};

\node[source](tmp_ref_3)[below=of tmp_dec]{7:t};

\draw[->] (x_ref.north) -- (x_dec.south);
\draw[->] (x_ref_2.north) -- (x_dec.south);
\draw[->] (tmp_ref.north) -- (tmp_dec_2.south);
\draw[->] (tmp_ref_2.north) -- (tmp_dec_2.south);
\draw[->] (tmp_ref_3.north) -- (tmp_dec_2.south);
\end{tikzpicture}
\end{minipage}

\caption{Target program generated by swap language extension and corresponding name graph} \label{fig:name-graph}
\end{figure}

Node \textit{7:t} and \textit{6:t} originate from the source program but reference a synthesized declaration. Node \textit{5:t} shadows the original declaration \textit{2:t}. \textit{name-fix} adds node \textit{5:t} to the list of declarations to be renamed. After the entire name graph is analyzed/generated all declarations from this list are rebound under free names (i.e. names not yet bound in the target program). Since \textit{7:t} and \textit{6:t} are not correct references of \textit{5:t} they are not renamed. The resulting name graph and target program are presented in figure \ref{fig:name-graph-fixed}  

\begin{figure}[h]
\centering
\begin{minipage}{0.25\linewidth}
\begin{lstlisting}
	var x = 0, 
		tmp = 1;
		
	(function() {
		var tmp$0 = x;
		x = tmp;
		tmp = tmp$0;
	})();
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.65\linewidth}
\begin{tikzpicture}[
source/.style={circle, draw=black, fill=white, very thick, minimum size=10mm},
synthesized/.style={circle, draw=black, fill=gray!60, very thick, minimum size=10mm}
]
\node[source](x_dec){1:x};
\node[source](tmp_dec)[right=of x_dec,xshift=7mm]{2:t};
\node[synthesized](tmp_dec_2)[right=of tmp_dec]{5':t'};

\node[source](x_ref)[below=of x_dec,xshift=7mm]{5:x};
\node[source](x_ref_2)[below=of x_dec,xshift=-7mm]{6:x};
\node[source](tmp_ref)[below=of tmp_dec,xshift=7mm]{6:t};
\node[synthesized](tmp_ref_2)[below=of tmp_dec_2]{7':t'};

\node[source](tmp_ref_3)[below=of tmp_dec,xshift=-7mm]{7:t};

\draw[->] (x_ref.north) -- (x_dec.south);
\draw[->] (x_ref_2.north) -- (x_dec.south);
\draw[->] (tmp_ref.north) -- (tmp_dec.south);
\draw[->] (tmp_ref_2.north) -- (tmp_dec_2.south);
\draw[->] (tmp_ref_3.north) -- (tmp_dec.south);
\end{tikzpicture}
\end{minipage}

\caption{Target program and name graph after \textit{name-fix} algorithm} \label{fig:name-graph-fixed}
\end{figure}

\textit{name-fix} does apply a \textit{"a closed-world assumption to infer that all unbound variables are indeed free, and thus can be renamed at will."}~\cite{Erdweg2014}. This means that global variables defined by the user (or a third-party library) that are included within the same run-time as our target program, could possibly be shadowed by the renamed bindings. However there is no way for \textit{name-fix} to know what bindings will be taken by other bindings than those bound in the source program.

\paragraph{Combined language extensions} \label{par:combined-extensions}
Language extensions can depend upon other language extensions to work correctly, this dependency makes a collection of language extensions less modular because the depended extension always needs to be used in combination with it's dependency. It would be preferable if the two extensions could be used in separation where functionality which relies on both extensions working together is only enabled in a situation where the two language extensions are used.

An example of such overlapping functionality in the ES 6 specification is that of destructuring assignment (see appendix \ref{destructuring}) inside for-of loops (see appendix \ref{for-of}).

\begin{lstlisting}
for(var [a,b] of [ [1,2], [3,4] ]) {
	// ... do something with a and b
}
\end{lstlisting}

The for-of loop needs a dependency on the destructuring assignment syntax definition, to be able to create the statement syntax to allow an assignment pattern (i.e. either an array or object destructuring) inside the for-of loop:

\begin{lstlisting}
syntax Statement 
	= "for" "(" "var" AssignmentPattern "of" Expression ")" Statement;
\end{lstlisting}

Shared language extensions need to have a non-terminal defined in the base-language which can be extended in both language extensions. In case of the for-of loop we can introduce a new non-terminal \textit{ForBinding} which can be extended in the destructuring assignment language extension.

\begin{lstlisting}
// Core syntax definition
syntax ForBinding
	= Id;

// For-of loop language extension
syntax Statement
	= "for" "(" "var" ForBinding "of" Expression ")" Statement;
	
// Destructuring language extension
syntax ForBinding
	= AssignmentPattern;
\end{lstlisting}

Designing language extensions in this way makes the entire suite of language extensions more modular, because we can combine language extensions that depend on each other for full functionality. Or use them separately to get only their independent functionality.
