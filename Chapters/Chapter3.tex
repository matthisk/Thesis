% Chapter Template

\chapter{Transforming ECMAScript} % Main chapter title

\label{Chapter3}

\lhead{Chapter 3. \emph{Transforming ECMAScript}}

\section{Motivating Examples}

The Babeljs compiler visits each AST node, functions inside of a specific transformation can announce themselves for the callback stack of a node visit. The callback to this function receives several arguments (current AST node, parent AST node, current Scope, and the file being transformed). The Scope class has functions presented in \ref{babel-scope}, if a node transformation wants to introduce a new variable say $ref$ it calls $generateUidIdentifier$ with String $ref$ as an argument on Scope and receives a name which is not bound in the current Scope. For this to work the visitor needs to have information of all the variables bound in the current scope. This makes the transformation more a full compiler than a set of transformation rules. For starters the transformation code needs to be aware of the Scope class and its functions. 

\begin{lstlisting}[label=babel-scope, caption={Variable capture avoidance code from babeljs source\protect\footnotemark}]
  generateUidIdentifier(name: string) {
    return t.identifier(this.generateUid(name));
  }

  generateUid(name: string) {
    name = t.toIdentifier(name).replace(/^_+/, "");

    var uid;
    var i = 0;
    do {
      uid = this._generateUid(name, i);
      i++;
    } while (this.hasBinding(uid) || this.hasGlobal(uid) || this.hasReference(uid));


    var program = this.getProgramParent();
    program.references[uid] = true;
    program.uids[uid] = true;

    return uid;
  }

  _generateUid(name, i) {
    var id = name;
    if (i > 1) id += i;
    return `_${id}`;
  }
\end{lstlisting}
\footnotetext{\href{https://goo.gl/BZKIvV}{https://goo.gl/BZKIvV}}

The Traceur compiler totally ignores the problem of variable capture. In conformance with the case study conducted by Erdeweg et. al. \cite{Erdweg2014} we were able to identify a transpiler that fails to address variable capture. With a simple example we can demonstrate the introduction of capture by Traceur \ref{traceur-capture}

\begin{lstlisting}[label=traceur-capture, caption=Example input to Traceur\protect\footnotemark]
function f() {
  var $__0 = 0;
  var x = () => this; 
}
\end{lstlisting}
\footnotetext{\href{https://goo.gl/Ds3xUn}{https://goo.gl/Ds3xUn}}

\begin{lstlisting}[caption=Variable capture]
function f() {
    var $__0 = this;
    var $__0 = 0;
    var x = (function() {
      return $__0;
    });
  }
\end{lstlisting}

\section{Taxonomy of language features}

Every language extension has several properties which can be identified and categorized along certain dimensions. In this chapter we present such a taxonomy for all the language extensions presented in the ECMAScript 6 specification\cite{SpecJS}.

\subsection{Dimensions}
The following dimensions are identified and used to categorize every language extension.

\paragraph{Category}
One of the rephrasing categories defined by Eelco Visser\cite{Visser2001}, rephrasings are program transformations that transform, where the source and target program language are the same. We identify the following categories:
\\ 

\begin{table}[h]
\centering
\caption{Taxonomy categories}
\label{table-taxonomy-category}
\begin{adjustbox}{width=1\textwidth}
\begin{tabular}{rl}
\multicolumn{1}{l}{Normalization} &                                                                                                                                                                               \\ \hline
{\bf Desugaring}                  & is a form of normalization. With a desugaring language constructs (called syntactic sugar) are reduced to a core language.                                                    \\
{\bf Simplification}              & this is a more generic form of normalization in which parts of the program are transformed to a standard form (e.g. removing an if statement which always evaluates to false) \\
{\bf Weaving}                     &                                                                                                                                                                               \\
\multicolumn{1}{l}{Optimization}  & These transformations help improve the run-time and/or space performance of a program                                                                                         \\ \hline
{\bf Specialization}              &                                                                                                                                                                               \\
{\bf Inlining}                    &                                                                                                                                                                               \\
{\bf Fusion}                      &                                                                                                                                                                               \\
\multicolumn{1}{l}{Other}         &                                                                                                                                                                               \\ \hline
{\bf Refactoring}                 & "is a disciplined technique for restructuring an existing body of code, alteringits internal structure without changing its external behaviour."\footnotemark                 \\
{\bf Obfuscation}                 & is a transformation that makes output code less (human) readable, while not changing any of the semantics.                                                                    \\
{\bf Renovation}                  & is a special form of refactoring, "to repair an error or to bring it up to date with respect to changed requirements"\cite{Visser2001}                                                
\end{tabular}
\end{adjustbox}
\end{table}

\paragraph{Abstraction level}
Program transformations can be categorized by their abstraction level. There are four levels of abstraction (similar to those of macro expansions\cite{Weise1993}), character-, token-, syntax-, or semantic-based. Character and token based transformations work on a program in textual representation. Syntactical transformations work on a program in its parsed representation (either as an AST or as a parse tree \ref{program-representation}). Next to the syntactic representation semantic transformations also have access to the static semantics of the input program (e.g. variable binding).

\paragraph{Purely semantic}
Is the extension purely in semantic, or does the extension introduce new syntax.

\paragraph{Scope}
Program transformations can happen within four different scopes: 

When a program transformation matches on a sub-tree of the parse tree and only transforms this matched sub-tree it is a local-to-local transformation. If the transformation needs information outside the context of the matched sub-tree, but only transforms the matched sub-tree it is global-to-local. When a transformation has no additional context from its local sub-tree but does alter the entire parse tree it is called local-to-global.If the transformation transforms the input program in its entirety it is global-to-global.  

\paragraph{Syntactically type preserving}
Program transformations performed on syntax elements (i.e. being syntax- or semantic based) can preserve the syntax type of their input element or alter it (e.g. is an expression transformed to an expression, or to a list of statements)

\paragraph{Introduction of bindings}
Are new bindings introduced in the transformed code as opposed to the original code.

\paragraph{Depending on bindings (i.e. run-time code)}
Will the transformed code rely on function calls not introduced by the transformation itself but provided separately from the transformation suite.

\paragraph{Compositional}
When a program transformation does not alter the containing context of the matched node, it is said to be compositional.

\paragraph{Preconditions}
What are the preconditions that have to be met before execution of a transformation rule, to ensure validness of our transformation (e.g. all sub-terms have to be analyzed and transformed)

\paragraph{Restrictions on sub-terms}
Does the language extensions impose restrictions on the sub-terms used inside of the language extension. 

\paragraph{Analysis of sub-terms}
Are the non-terminals of our language extension analyzed and possibly transformed by the transformation rule.

\paragraph{Dependency on other extensions}
Can the language extensions be performed stand-alone or is there a dependency on one of the other extensions.

\paragraph{Backwards compatible}
Is the API of the transformed code compatible with the ECMAScript 6 specification (i.e. can we import a transformed module in ECMAScript 6 and use it properly).

\paragraph{Dividable}
Is it possible to identify smaller transformation rules inside this language extension, that can be performed independently from one another.

\afterpage{%
	\clearpage
	\thispagestyle{headings}
	
	\begin{landscape}		
		\centering

		\begin{table}[h]
		\caption{ES6 features transformation dimensions (1/2)}
		\label{full-table-1}

\begin{tabular}{rcccccc}
\hline
                                                    & {\bf Arrow Functions} & {\bf Classes} & {\bf Destructuring} & {\bf Object literals} & {\bf For of loop} & {\bf Spread operator} \\ \hline
{\bf Category}                              & D.                    & D.            & D.                  & D.                    & D.                & D.                    \\
{\bf Abstraction level}                   & CfS.                  & CfS.          & CfS.                & CfS.                  & CfS.              & CfS.                  \\
{\bf Scope}                                   & L2L                   & L2L           & L2L                 & L2L                   & L2L               & L2L                   \\
{\bf Syntactically type preserving}  & $\bullet$             & $\bullet$     & $\circ$             & $\bullet$             & $\bullet$         & $\bullet$             \\
{\bf Introducing bindings}               & $\bullet$             & $\circ$       & $\bullet$           & $\circ$               & $\circ$           & $\bullet$             \\
{\bf Depending on bindings}            & $\circ$               & $\bullet$     & $\bullet$           & $\circ$               & $\circ$           & $\bullet$             \\
{\bf Compositional}                        & $\bullet$             & $\bullet$     & $\bullet$           & $\bullet$             & $\bullet$         & $\bullet$             \\
{\bf Analysis of subterms}              & $\bullet$             & $\bullet$     & $\bullet$           & $\circ$               & $\circ$           & $\bullet$             \\
{\bf Constraints on subterms}         & $\circ$               & $\bullet$     & $\circ$             & $\circ$               & $\circ$           & $\circ$               \\
{\bf Preconditions}                         & $\bullet$             & $\bullet$     & $\circ$             & $\circ$               & $\circ$           & $\circ$               \\
{\bf Dependencies}                        & $\circ$               & $\circ$       & $\bullet$           & $\circ$               & $\bullet$         & $\circ$               \\
{\bf Backwards compatible}             & $\bullet$             & $\bullet$     & $\bullet$           & $\bullet$             & $\bullet$         & $\bullet$             \\
{\bf Dividable}                                & $\circ$               & $\circ$       & $\bullet$           & $\bullet$             & $\bullet$         & $\bullet$             \\ \hline
\end{tabular}
\vspace*{0.5cm}
\newline

\begin{tabular}{rccccc}
\hline
                                                    & {\bf Default parameters} & {\bf Rest parameters} & {\bf Template Literals} & {\bf Generators} & {\bf Let Const} \\ \hline
{\bf Category}                              & D.                       & D.                    & D.                      & D.               & U.              \\
{\bf Abstraction level}                  & CfS.                     & CfS.                  & CfS.                    & CfS.             & S.              \\
{\bf Scope}                                  & L2L                      & L2L                   & L2L                     & L2L              & L2L             \\
{\bf Syntactically type preserving} & $\bullet$                & $\bullet$             & $\bullet$               & $\bullet$        & $\bullet$       \\
{\bf Introducing bindings}              & $\circ$                  & $\circ$               & $\circ$                 & $\circ$          & $\circ$         \\
{\bf Depending on bindings}          & $\circ$                  & $\circ$               & $\circ$                 & $\bullet$        & $\circ$         \\
{\bf Compositional}                       & $\bullet$                & $\bullet$             & $\bullet$               & $\bullet$        & $\circ$         \\
{\bf Analysis of subterms}             & $\circ$                  & $\circ$               & $\circ$                 & $\bullet$        & $\bullet$       \\
{\bf Constraints on subterms}        & $\circ$                  & $\circ$               & $\circ$                 & $\circ$          & $\circ$         \\
{\bf Preconditions}                        & $\circ$                  & $\circ$               & $\circ$                 & $\bullet$        & $\bullet$       \\
{\bf Dependencies}                       & $\circ$                  & $\circ$               & $\circ$                 & $\circ$          & $\circ$         \\
{\bf Backwards compatible}           & $\bullet$                & $\bullet$             & $\bullet$               & $\bullet$        & $\circ$         \\
{\bf Dividable}                              & $\circ$                  & $\circ$               & $\circ$                 & $\circ$          & $\bullet$       \\ \hline
\end{tabular}
	\end{table}

		
	\end{landscape}
	\clearpage
}

\subsection{On the expressive power of ECMAScript 6}
Matthias Felleisen presents a rigorous mathematical framework to define the expressiveness of programming languages (as compared to each other) in his paper "On the expressive power of programming languages"\cite{Felleisen1990}. 

The formal specification presented by Felleisen falls outside of the scope of this thesis. But we can summaries his findings informally: If a construct in language $A$ can be expressed in a construct in language $B$ by only performing local transformations (local-to-local). Language $A$ is no more expressive than language $B$. And \textit{"By the definition of an expressible construct, programs in a less expressive language generally have a globally different structure from functionally equivalent programs in a more expressive language."}\cite{Felleisen1990} 

\textit{"Intuitively, a programming language is less expressive than another if the latter can express all the facilities the former can express in the language universe."}\cite{Felleisen1990}

How is this applied to the ECMAScript 6 standard. Every new language feature can be transformed to a construct with similar semantics in ECMAScript 5 with a local-to-local transformation. With the exception of the let-const\ref{let-const} extension.

\section{Implementation}
Each transformation is defined as a term-rewriting rule. It has a concrete syntax pattern which can match part of a parse-tree. The result is a concrete piece of syntax, using only constructs from the fundamental syntax definition (i.e. ECMAScript 5).
The rewrite rules are exhaustively applied on the input parse-tree until no more rewrite rules match any sub-trees of the input (constraint solving). Application of rewrite rules to the parse tree is done bottom-up, because several rewrite rules (e.g. \ref{arrow-function-table}) demand for successful completion that their sub-terms are already transformed.

\subsection{cross-cutting concerns}
Each transformation rule has to deal with similar issues, can we identify these issues and solve them in a standalone (language agnostic) fashion?
Many problems with transformations originate with name binding in source and target language.

\paragraph{Variable capture}
What happens when a transformation rule introduces a new binding. There are two possibilities either the binding-name is not yet bound in the source program, or the binding-name is already bound in the source program. In the second case our transformation code introduces \textit{variable capture}. This can be illustrated with the use of a simple example.

\begin{minipage}{0.45\textwidth}
\begin{lstlisting}[caption=Input JavaScript]
var {x} = obj;
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
\begin{lstlisting}[caption=Desugared JavaScript]
var _ref = obj;
var x = _ref.x;
\end{lstlisting}
\end{minipage}

For this example we look at destructuring variable declaration (see: \ref{destructuring}). During the transformation a new binding is created to store the object (named \_ref). 

If however the name \_ref was already bound in our source program this would result in an illegal redeclaration of \_ref. This problem is identified as variable capture and can arise for any piece of transformation code, were source and target language have name binding.

What are some possible solutions for this problem. Let each transformation deal with the avoidance of variable capture. Build full scope tree and supply this scope to our \textit{desugaring} functions, generate new identifiers that are unique in the scope. Disadvantage of this solution is that programmers creating transformation code need also be capable of creating scope trees, and our transformer start to have more resemblance with full fledged compiler than term-rewriting rules.

The solution presented by Erdweg et. al.\cite{Erdweg2014a} is called \textit{name-fix}, this is a standalone algorithm that does not interfere with transformation code. It identifies variable capture through the use of string origin\cite{Inostroza2014} information stored in the parse tree.

\paragraph{Introducing (multiple) bindings}
As described above various desugarings have to introduce bindings for correct transformation. In most cases new bindings will be bound to some descriptive variable name (e.g. \_ref). If a language extension is used multiple times within the same scope the same identifier will be declared multiple times. This is a similar problem to that of variable capture, but the capture now happens with binding all introduced by transformation code. And not from a transformation to source binding. Similar to the variable capture problem this problem could be solved uniquely for every transformation, or can be extracted and solved in a generic manner (i.e. agnostic from transformation code). 

Supply each \textit{desugar} function with a function called \textit{generateUId} (generate unique identifier). When a transformation wants to generate a identifier (.e.g \_ref), it calls this function (which has knowledge of all previously generated identifiers) and generates a unique identifier through the use of \textit{gensym}\ref{gen-sym} algorithm.  

\paragraph{Introducing new bindings}
Many transformations introduce new bindings to store some intermediate value needed for our transformation. These bindings should be introduced in the containing block-scope where our transformation is performed. With the use of annotations on the parse tree we can set declarations on our current matched node. A final pass over the tree will take care of setting declarations in the correct block scope.
