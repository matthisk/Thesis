% !TEX root = ../main.tex
% Chapter Template

\chapter{Background} % Main chapter title

\label{Chapter2}

\lhead{Chapter 2. \emph{Background}}

\section{ECMAScript}
JavaScript\footnotemark is the programming language implemented from the ECMAScript specification\cite{SpecJS}. JavaScript is an interpreted, object-oriented, dynamically typed scripting language with functions as first-class citizens. It is mostly used inside the Web browser, but also available for non browser environments (e.g. node.js). In this section we will identify some of the key characteristics of the JavaScript programming language.
\footnotetext{Documentation on the JavaScript programming language can be found at the \href{https://developer.mozilla.org/en-US/docs/Web/JavaScript}{Mozilla Developer Network}}

\paragraph{Syntax} \label{javascript-syntax}
One of the main concerns for program transformations is syntax. The syntax of the programming language is to be extended to support new language features/constructs. ECMAScript falls in the C-type family % TODO: citation
of syntax definitions (i.e. it uses curly braces to delimit blocks of code).
A program exists of a list of \textit{statements}. A \textit{statement} can be one of the language control flow constructs, a declaration, a function, or an \textit{expression}. Functions in JavaScript can be either defined as an \textit{expression} or as a \textit{statement} (see section \ref{javascript-functions}). The ES standard specifies automatic semicolon insertion (or ASI), this grammar feature makes it possible for programmers to omit the the trailing semicolon after statements and let the parser insert these automatically.

\paragraph{Inhertiance \& Object orientation} \label{javascript-inheritance}
JavaScript can be classified as an object oriented language without \textit{class} based inheritance model\footnote{Most popular object-oriented languages do have \textit{class} based inheritance (e.g. Java or C++)}. Instead of such a model JavaScript objects have a prototype chain that determine their inheritance.

In the JavaScript run-time environment everything is an object with properties (even functions see section \ref{javascript-functions}), with the exception of primitive data-types (e.g. numbers). Every object has one special property called the \textit{prototype}, this prototype references another object (with yet another prototype) until finally one object has prototype \textit{null}. This chain of objects is called the \textit{prototype chain}. When performing a lookup on an object for a certain key $x$, the JavaScript interpreter will look for property $x$ on our object, if $x$ is not found it will look at the \textit{prototype} of our object. This iteration will continue until either prototype \textit{null} is found or an object with property $x$ is found in the prototype chain.

To understand prototypal inheritance in comparison to class based inheritance, we can use an analogy. A class in a class based programming language can be seen as a blueprint from which to construct objects. When calling a function on an object created from such a blueprint the function is retrieved from the blueprint and not from the (constructed) object. So the object is related to the class (or blueprint) with an object-class relation. With prototypal inheritance there is no blueprint everything is an object. This is also how inheritance works, we do not reference a blueprint but we reference a fully build object as our prototype. This creates an object-object relation.

If we have an object Car which inherits from Vehicle we set the Car's object prototype to an instance of the Vehicle object. Where in class based inheritance there is a blueprint for Car which inherits from the Vehicle blueprint, to build a car we initialize from the blueprint.

\begin{lstlisting}
var Vehicle = function() {...};
var Car = function() {...};

Car.prototype = new Vehicle();
\end{lstlisting}

\paragraph{Scoping} \label{javascript-scoping}
Most programming languages have some form of variable binding. These bindings are only bound in a certain context, such a context is often called a scope. There are two different ways to handle scope in a programming language, Lexical (or static) scoping and dynamic scoping. Lexical scoping is determined by the placing of a binding within the source program or its \textit{lexical context}. Variables bound in a dynamic scope are resolved through the program state or \textit{run-time context}.

In JavaScript bindings are determined through the use of lexical scoping, on a function level. Variables bound within a function's context are available throughout the entire lexical scope of the function, independent of their placement within this function (this is called hoisting).

One exception on the lexical scoping is binding of the \textit{this} keyword. Similar to many other object oriented languages JavaScript makes use of a \textit{this} keyword. In most object oriented languages the current object is implicitly bound to \textit{this} inside functions of that object.\footnote{Sometimes \textit{this} is called \textit{self} (e.g. in the \href{http://ruby.org}{Ruby} programming language)} In JavaScript the value of \textit{this} can change between function calls. For this reason the \textit{this} binding has dynamic scoping (we can not determine the value of \textit{this} before run-time).

\paragraph{Typing} \label{javascript-typing}
JavaScript is a dynamically typed language without type annotations. Each object can be typecast without the use of special operator(s) and will be be converted automatically to correct type during execution. There are 5 primitive types, everything is else is an object:

\begin{itemize}
	\item \textit{Boolean}
	\item \textit{null}
	\item \textit{undefined}
	\item \textit{Number}
	\item \textit{String}
\end{itemize}

\paragraph{Functions} \label{javascript-functions}
in JavaScript functions are objects. Because of this functions are automatically promoted to first-class citizens (i.e. they can be used anywhere and in anyway normal bindings can be used). This presents the possibility to supply functions as arguments to functions, and calling member functions of the function object. Every function object inherits from the \textit{Function.prototype}\footnote{For more information see \href{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/prototype}{Mozilla Developer Network}} which contains functions that allow the overriding of this binding (see section \ref{javascript-scoping}).

Another common pattern is JavaScript related to functions, is that of the immediately invoking function expression (IIFE). Functions in JavaScript can be defined either in a statement or in an expression. When a function is defined as an expression it is possible to immediately invoke the created function:

\begin{lstlisting}[title=IIFE,caption={Immediately invoking function expression}]
(function() {
	<Statement* body>
})()
\end{lstlisting}

\paragraph{Asynchronous}
JavaScript is a single-threaded language, this means that concurrency through the use of processes, threads, or similar concurrency constructs is not possible.

\section{Program Transformations}
Eelco Visser defines the aim of a program transformation as follows:

\blockquote[\cite{Visser2001}]{\textit{The aim of program transformation is to increase programmer productivity by automating programming tasks, thus enabling programming at a higher-level of abstraction, and increasing maintainability}}

There are many different types of program transformations. Programs can be transformed from a source to a target language. Where both can be the same or different. One can be a higher level language and one a lower level language. In this thesis we will focus on transformations in the category rephrasing~\cite{Visser2001}. Here a program in a source language is transformed to a different program in the same language.

\section{Language Extensions} \label{lang-ext}
\textit{"Language extensions augment a base language with additional language features."}~\cite{Erdweg2014}
With the use of program transformations these extensions can be eliminated and a target program in the base language can be produced. \textit{"Many compilers first desugar a source program to a core language."}~\cite{Erdweg2014} For example the Haskell functional programming language defines for many constructs how they can be transformed to a kernel language~\cite{PeytonJones}. These pieces of \textit{syntactic sugar} are examples of language extensions.

Language extensions are closely related to other forms of program transformations. There are (syntax) macros\cite{Leavenworth1966}, these are language extensions defined within the same source file and are expanded before compilation (examples are SweeterJS~\cite{Disney2014}, Syntax macros~\cite{Weise1993}). These \textit{"define syntactic abstractions over code fragments"}~\cite{Bravenboer2004}. Macro systems have several limitations. The transformations need to be present in the source file, macros are often restrained to a fixed invocation (through a macro identifier), and they often lack the expressiveness in their rewriting language\cite{Bravenboer2004}. There was an attempt to implement the ES6 specification through the use of syntax macros\footnote{\url{https://github.com/jlongster/es6-macros}} but the project is abandoned.

Most language extensions can be classified as syntactic sugar. As mentioned before there are several languages that before compilation are transformed to a core language (e.g. Haskell core language).  Language features classified as syntactic sugar, are features that can be expressed in the core language. But often benefit from improved human readability when notated with aid of the syntactic sugar. For example the assignment expression \lstinline$a += b$ is syntactic sugar notation for \lstinline$a = a + b$ this notation is often found in c-style programming languages.

\subsection{Hygiene} \label{hygiene}
Any program transformations that introduces new bindings in the target program risks the unintended shadow of user identifiers, or variable capture. When variable capture happens as a result of a program transformation, this transformation is unhygienic. Transformations that guarantee that no unintended variable capture will occur are called hygienic transformations. Hygienic program transformations are mostly studied in the context of macro expansions~\cite{Herman2010a,Herman2010,Disney2014}

The problem of variable capture can best be explained through the use of an example. Here we use a language extension called \textit{swap}, that can swap the values of two bindings with the use of a single statement. The transformation eliminates the \lstinline$swap$ statement and introduces an immediately invoking function expression (see section \ref{javascript-functions}) to swap out the values. In the body of this function we bind the value of one of the input variables to a temporary binding:

\begin{figure}[!h]
\begin{minipage}{0.45\textwidth}
	\begin{lstlisting}
	swap x y;
	\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
	\begin{lstlisting}
	(function() {
		var tmp = x; (*@\label{hygiene-tmp}@*)
		x = y;
		y = tmp;
	})();
	\end{lstlisting}
\end{minipage}

\caption{A language extension swap is transformed to core JavaScript}
\end{figure}

This transformation rule introduces a new binding named \lstinline$tmp$ (at line \ref{hygiene-tmp}). Because of this introduction the transformation could possibly generate variable capture in the target program. When one of the arguments of the \lstinline$swap$ statement is named \lstinline$tmp$ the transformation will shadow the users binding and not produce the expected result (see figure \ref{fig:unhygienic}).

\begin{figure}[!h]
\label{fig:unhygienic}
\begin{minipage}{0.45\textwidth}
	\begin{lstlisting}
	swap x tmp;
	\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
	\begin{lstlisting}
	(function() {
		var tmp = x;
		x = tmp;
		tmp = tmp;
	})();
	\end{lstlisting}
\end{minipage}
\caption{Introduction of variable capture because the transformation binds non-free name}
\end{figure}

The unhygienic transformation as explained above can often introduce subtle bugs in target programs, which are hard to identify for the user of the program transformation. Especially in the context of real-world applications, because of the complexity of the source program, and the transformation suite. Many transformations suites fail to identify and solve variable capture in their program transformations, in a case study performed by Erdweg et. al. eight out of nine implementations of a Domain Specific Language were prone to variable capture~\cite{Erdweg2014a}.

\section{Program Representation} \label{program-representation}
Before programs can be transformed they need a structured representation. Seldom are program transformations performed on the the textual input. Here we discuss several ways to represent programs.

\paragraph{Parse Trees}
Parse trees represent a program's syntactic information in a tree. This tree includes layout information of the input program (e.g. white-space, comments). The parse tree is structured according to some context-free grammar, that defines how to parse textual input.

\paragraph{Abstract Syntax Tree}
or AST is produced by removing layout information from a parse tree, only the core constructs of the language grammar remain as nodes in the tree. White-space layout, comments, and things like parentheses (these are implicitly implied by the structure of the AST) are removed. An AST is often the input for compiler pipelines, program transformations, and refactorings.

\paragraph{Higher Order Syntax Trees (HOAS)}
To represent not just a program's sub expression relations but also its variable binding we can use a Higher Order Syntax Tree (HOAS)\cite{Pfenning1988}. In a HOAS the variable bindings are made explicit (just as the sub expression relations are made explicit in an AST). Every variable has a binding-site and possibly uses throughout the rest of the tree. \textit{"In addition to dealing with the problem of variable capture, HOAS provides higher-order matching which synthesizes new function for higher-order  variables. One of the problems of higher-order matching is that there can be many matches for a pattern"}~\cite{Visser2001}

\section{Parsing} \label{parsing}
Before a program is represented in on of the previously defined tree formats, it is represented in textual form. To transform the stream of input characters to a tree a program called a parser is used. There are many different types of parser techniques, and a large body of research~\cite{Visser1997,VandenBrand2002,Salomon1989}

The parsing of textual input often happens in two stages. First a \textit{scanner} performs the lexical analysis, which identifies the tokens of our syntax (e.g. keywords, identifiers). With this identification the parser operates on the identified tokens. Usually the lexical syntax of a language is \textit{"specified by regular expression"}~\cite{Bravenboer2004}.

Scanners that do not have access to the parser, are also unaware of the context of lexical tokens. In case of JavaScript this can impose subtle difficulties in the implementation of a scanner. \textit{"due to ambiguities in how regular expression literals (such as /[0-9]*/) and the divide operator (/) should be lexed."}~\cite{Disney2014}. For this reason traditional JavaScript parsers are often intertwined with their lexer. Disney et. al. avoid this problem by introducing a separate reader stage in the parser. This problem can also be avoided by using scannerless parsing, \textit{"Scannerless parsing is a parsing technique that does not use a scanner to divide a string into lexical tokens. Instead lexical analysis is integrated in the context-free analysis of the entire string."}~\cite{Visser1997} these parsers preserve the lexical structure of the input characters, and make it possible to compose grammars~\cite{Visser1997}.

There exist different types of parsers, where some can handle more grammars than others. Examples of parser types are LR (left to right), SLR (simple left to right), LALR (look-ahed left to right), or CLR (canonical left to right). Each of these parsers uses a parse table which contains all the knowledge of the grammar that has to be parsed. Now the parser is a loop over the input using the parse table to identify possible next symbols.

Scannerless parsing suffers form conflicts in the parse table~\cite{Visser1997}, there are two causes for these conflicts, either there exists an ambiguity in the grammar, or lack of look-ahead. This second case occurs when a choice from the parse table is incorrect, but this can not be determined by the parser inside its current look-ahead window. Generalized parsers solve this problem by foking new parsers for each conflict found in the parse table, when all forked parsers finish correctly the parser outputs a parse forest (instead of a parse tree). When conflict arose from lack of look-ahead the forked parser for this conflict will fail.

\section{Language Workbenches} \label{rascal}

Language workbench is a term popularized by Martin Fowler and we can summarize his definition as follows:

A language workbench makes it easy to build tools that match the best of modern IDEs, where the primary source of information is a persistent abstract representation. Its users can freely design new languages without a semantic barrier, with the result of language oriented programming becoming much more accessible.~\cite{Fowler2005}

These workbenches improve the efficiency of language oriented programming~\cite{Ward1994} significantly, by giving programmers the the tools to define programming languages with an abstract representation.

The Rascal~\cite{Klinta} meta-programming environment is a language workbench. It allows programmers to define context-free grammars, generate parsers for these grammars. The workbench integrates with the Eclipse development environment, which allows meta-programmers to integrate interactive language-specific IDE features and syntax highlighting. All language extensions presented in this thesis are implemented using the Rascal meta-programming environment.

\paragraph{Syntax definition}
Syntax definitions in Rascal allows the definition of parsers for programming languages or domain-specific languages. Rascal generates scannerless parsers from the context-free syntax definition (see section \ref{parsing}). Rascal uses generalized parsing to avoid lack of look-ahead, when the parser detects an ambiguity in its parse table, two parsers are forked from the main parser. In case of ambiguity a parse forest is returned, in case of lack of look-ahead error this parser fails (see section \ref{parsing}).

\paragraph{Concrete syntax}
A Rascal generated parser returns a parse tree (or forest), which is an ordered, rooted tree that represents the syntactic structure of a string according to the formal grammar used to specify the parser. Most transformation systems would implode this concrete syntax tree to an AST and perform program transformations on this tree. Rascal gives the possibility to perform program transformation directly on the concrete syntax tree through the use of concrete-syntax patterns. This has multiple advantages over an AST based solution:
\begin{itemize}
	\item Preserving layout information encoded in the concrete-syntax tree
	\item Avoiding the use of a pretty printer to output the transformed AST to a textual representation
	\item Rewrite rules can use concrete syntax patterns for their definition, improving human readability of transformation code
\end{itemize}
A concrete-syntax pattern may contain variables in the form of a grammars non-terminals, these variables are bound in the context of the current patterns use if the pattern is matched successful. A quoted concrete-syntax pattern starts with a non-terminal to define the desired syntactic type (e.g. Expression), and they ignore layout.

\begin{lstlisting}
(Symbol)`Token1 Token2 ... Token3` := pt
\end{lstlisting}

Where a token can be a lexical token, typed variable pattern: \lstinline$<Type Var>$, or a bound variable pattern \lstinline$<Var>$ (where \lstinline$Var$ is already bound in the current context, resolved and used as a pattern). And \lstinline$Symbol$ is a non-terminal.

Rascal supports a shorthand notation to parse a string starting from a non-terminal: (where \lstinline$"..."$ is any string)

\begin{lstlisting}
[Symbol]"..."
\end{lstlisting}
